# -*- coding: utf-8 -*-
"""Summer 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/136IWlozmMInNCGfOaMYInxzFNm3ra2s7
"""

#!pip install openai

"""Change the query text and try a few on your own. 


**Another Example**

We don't have enough time to introduce you to coding approaches to web scraping, but there are some brilliant tools out there. With them, you can program activities on the web - how a bot traverses the web, the resources it accesses and when, and then where it stores data. 

Let's take an example from the NYS Department of Health. Here is how they are [publishing their Monkeypox numbers.](https://health.ny.gov/diseases/communicable/zoonoses/monkeypox/) What do you think?

<img src="https://github.com/cocteau/CJ2022/raw/main/images/Screen%20Shot%202022-07-20%20at%206.43.13%20AM.png" width=800>

So assume we want to scrape this information every day. We could set up a scheduled WebScraper or we could do it in code.
"""

from requests import get
from bs4 import BeautifulSoup

# issues an HTTP "get" request in code
response = get("https://health.ny.gov/diseases/communicable/zoonoses/monkeypox/")

# now use BeautifulSoup to identify a portion of the page we want. 
# we can do this manually or with the help of Selector Gadget
bs = BeautifulSoup(response.text)

# now "subset" the part you're looking for by selecting just the 
# component of the page you're after

stats = bs.select_one(".box p")
# what we have is a portion of the page, the piece that contains the daily stats

"""To this, we can apply so-called natural language processing. In this case, we will use GPT-3 from OpenAI. Sign up for an account here (you get free credits)https://beta.openai.com/.

<img src="https://github.com/cocteau/CJ2022/raw/main/images/Screen%20Shot%202022-07-20%20at%207.22.24%20AM.png" width=800>

All of this can be accessed in code via OpenAI's API or Application Programming Interface. Instead of scraping data that was formatted for some other purpose, we can ask nicely for the data service we want and get the result back in a tidy format.
"""

import os
import openai

text = stats.get_text()+"\n Create a CSV of place and count. \nPlace,Count "

openai.api_key = ""

response = openai.Completion.create(
  model="text-davinci-002",
  prompt= text,
  temperature=0.7,
  max_tokens=256,
  top_p=1,
  frequency_penalty=0,
  presence_penalty=0
)

table_data = response["choices"][0]["text"]

from pandas import read_csv
from io import StringIO

# take the string we received from OpenAI and read the CSV text into a DataFrame
# oh and name the columns Place and Count
df = read_csv(StringIO(table_data),names=["Place","Count"])

from tabulate import tabulate
print(df.to_csv("2022-07-22.csv",index=False))

